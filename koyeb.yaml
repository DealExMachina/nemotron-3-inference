# Koyeb Service Configuration for Nemotron 3 Nano
# Deploy with: koyeb service create -f koyeb.yaml

name: nemotron-3-inference
type: WEB

definition:
  name: nemotron
  
  # Docker image configuration
  # Public Docker Hub image - no registry secret needed
  docker:
    image: jeanbapt/nemotron-3-inference:latest

  # Environment variables
  env:
    - key: HF_TOKEN
      secret: hf-token
    - key: VLLM_ATTENTION_BACKEND
      value: FLASHINFER

  # GPU instance configuration
  # IMPORTANT: FP8 quantization requires compute capability 89+
  # A100 (capability 80) does NOT work - use H100 (90) or L40S (89)
  instance_types:
    - type: gpu-nvidia-h100

  # Deployment regions
  # GPU availability varies by region
  regions:
    - sfo  # San Francisco - GPU availability

  # Port configuration
  ports:
    - port: 8000
      protocol: http

  # Route configuration
  routes:
    - path: /
      port: 8000

  # Health check configuration
  health_checks:
    - http:
        path: /health
        port: 8000
      grace_period: 300  # 5 minutes - model loading takes time
      interval: 30
      timeout: 10
      restart_limit: 3

  # Scaling configuration
  # min: 0 enables scale-to-zero for cost savings
  # max: 1 for single instance (GPU models are expensive)
  scalings:
    - min: 0
      max: 1
      targets:
        - requests_per_second:
            value: 10
        # Scale to zero after 15 minutes of idle
        - sleep_idle_delay:
            value: 900

